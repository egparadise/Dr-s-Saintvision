# DR-Saintvision Environment Configuration
# Copy this file to .env and modify as needed

# ============================================
# Model Settings
# ============================================

# Use Ollama for local model inference (recommended for easier setup)
USE_OLLAMA=true

# Hugging Face token (required for Llama models)
# Get your token at: https://huggingface.co/settings/tokens
HF_TOKEN=

# Model quantization (4-bit recommended for 12GB GPU)
USE_QUANTIZATION=true
QUANTIZATION_BITS=4

# ============================================
# Server Settings
# ============================================

# API Server
API_HOST=0.0.0.0
API_PORT=8000

# Gradio UI
GRADIO_HOST=0.0.0.0
GRADIO_PORT=7860
GRADIO_SHARE=false

# Ollama Server (if using Ollama)
OLLAMA_HOST=localhost
OLLAMA_PORT=11434

# ============================================
# Database Settings
# ============================================

DATABASE_PATH=./data/dr_saintvision.db

# ============================================
# Search Settings
# ============================================

SEARCH_MAX_RESULTS=5
SEARCH_TIMEOUT=30

# ============================================
# Debug Settings
# ============================================

DEBUG=false
LOG_LEVEL=INFO

# ============================================
# Performance Settings
# ============================================

# Run search and reasoning in parallel
PARALLEL_ANALYSIS=true

# Maximum debate timeout (seconds)
DEBATE_TIMEOUT=300
